{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a04504e-4021-45ae-8788-580d052d089c",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725c3f52-e1fb-4978-81ce-933f9c928358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 22:25:04.855102: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-26 22:25:04.855175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-26 22:25:04.856289: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-26 22:25:04.863494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import os, tensorflow as tf\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "from evaluation import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92942f37-3dbc-4623-aed3-d86bbd2debad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    TextVectorization, Embedding, Conv1D, GlobalMaxPooling1D,\n",
    "    Dense, Dropout, Input, MaxPooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d36760-c4a4-4fe8-95d5-169bdd75e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv A Example:\n",
      " What is a foreign exchange crisis? What are some notable examples?\n",
      "A foreign exchange crisis refers to a situation where a country faces severe shortage of foreign currencies, usually dollars or euros\n",
      "Conv B Example:\n",
      " What is a foreign exchange crisis? What are some notable examples?\n",
      "A foreign exchange crisis, also known as a currency crisis or balance of payments crisis, occurs when a country's currency experience\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "try:\n",
    "    CFG\n",
    "except NameError:\n",
    "    class CFG:\n",
    "        seeds = [42, 119, 2020, 2024, 2028]\n",
    "        \n",
    "train_df, test_df, y, class_names = load_and_prepare_data()\n",
    "pairs_train, pairs_val, test_pairs, y_train, y_val = prepare_dual_conversation_pipeline(train_df, test_df, y)\n",
    "\n",
    "print(\"Conv A Example:\\n\", pairs_train[0][0][:200])\n",
    "print(\"Conv B Example:\\n\", pairs_train[0][1][:200])\n",
    "print(\"Label:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2742a2d4-9703-4121-b587-90d0c16518f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 22:25:21.439616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38367 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0\n",
      "2025-11-26 22:25:21.442031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38367 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer (shared across the two inputs)\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vocab_size = 20000\n",
    "max_length = 512\n",
    "\n",
    "adapt_strings = [p[0] for p in pairs_train] + [p[1] for p in pairs_train]\n",
    "adapt_ds = tf.data.Dataset.from_tensor_slices([str(t) for t in adapt_strings]).batch(1024)\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "text_vectorizer.adapt(adapt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473d51b2-47dd-41c2-8710-ae061016ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data pipelines for ((A,B), y)\n",
    "def make_dual_dataset(pairs, labels=None, batch_size=128, training=True):\n",
    "    part_a = [str(p[0]) for p in pairs]\n",
    "    part_b = [str(p[1]) for p in pairs]\n",
    "\n",
    "    inputs = {\"inp_a\": tf.constant(part_a), \"inp_b\": tf.constant(part_b)}\n",
    "\n",
    "    if labels is None:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    else:\n",
    "        labels = np.asarray(labels, dtype=np.int32)\n",
    "        ds = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "\n",
    "    if labels is not None and training:\n",
    "        ds = ds.shuffle(2048, reshuffle_each_iteration=True)\n",
    "\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_dual_dataset(pairs_train, y_train, training=True)\n",
    "val_ds   = make_dual_dataset(pairs_val,   y_val,   training=False)\n",
    "test_ds  = make_dual_dataset(test_pairs,  labels=None,  training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62a1b71-9c02-4b24-8b25-c79cec2bdac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (two string inputs â†’ vectorizer â†’ shared embedding â†’ concat â†’ conv)\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, MaxPooling1D, Concatenate, Add\n",
    "\n",
    "def res_block(x, filters, use_projection=False):\n",
    "    shortcut = x\n",
    "    out = Conv1D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    out = Conv1D(filters, 3, padding=\"same\")(out)\n",
    "\n",
    "    if use_projection or shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding=\"same\")(shortcut)\n",
    "\n",
    "    out = Add()([out, shortcut])\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "    \n",
    "def conv_block(x, filters, use_residual=False, pool=True):\n",
    "    if use_residual:\n",
    "        x = res_block(x, filters, use_projection=True)\n",
    "    else:\n",
    "        x = Conv1D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    if pool:\n",
    "        x = MaxPooling1D()(x)\n",
    "    return x\n",
    "    \n",
    "def get_dual_cnn_model(vocab_size=vocab_size, embed_dim=64, num_classes=3):\n",
    "    inp_a = Input(shape=(), dtype=tf.string, name=\"inp_a\")\n",
    "    inp_b = Input(shape=(), dtype=tf.string, name=\"inp_b\")\n",
    "\n",
    "    # shared layers\n",
    "    emb = Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
    "\n",
    "    # branch A\n",
    "    xa = text_vectorizer(inp_a)\n",
    "    xa = emb(xa)\n",
    "    \n",
    "    # Conv32Ã—2 â†’ MP\n",
    "    xa = conv_block(xa, 32, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv64Ã—2 â†’ GMP\n",
    "    xa = conv_block(xa, 64, use_residual=True, pool=False)\n",
    "    xa = GlobalMaxPooling1D()(xa)\n",
    "\n",
    "    # branch B\n",
    "    xb = text_vectorizer(inp_b)\n",
    "    xb = emb(xb)\n",
    "\n",
    "    # Conv32Ã—2 â†’ MP\n",
    "    xb = conv_block(xb, 32, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv64Ã—2 â†’ GMP\n",
    "    xb = conv_block(xb, 64, use_residual=True, pool=False)\n",
    "    xb = GlobalMaxPooling1D()(xb)\n",
    "\n",
    "    # merge\n",
    "    x  = Concatenate()([xa, xb])\n",
    "    x  = Dropout(0.3)(x)\n",
    "    x  = Dense(128, activation=\"swish\")(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=[inp_a, inp_b], outputs=out)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da7f1d1-23be-41a0-9f7b-4c4c61bcc7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training new model for seed 42...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 22:25:29.728093: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-11-26 22:25:30.257593: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-11-26 22:25:30.335167: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-11-26 22:25:31.538877: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ff1b40003b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-26 22:25:31.538920: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2025-11-26 22:25:31.538925: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2025-11-26 22:25:31.550840: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764217531.626552 3951727 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - ETA: 0s - loss: 1.0876 - accuracy: 0.3895\n",
      "Epoch 1: val_loss improved from inf to 1.07379, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_42.keras\n",
      "360/360 [==============================] - 44s 105ms/step - loss: 1.0876 - accuracy: 0.3895 - val_loss: 1.0738 - val_accuracy: 0.4219\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0444 - accuracy: 0.4617\n",
      "Epoch 2: val_loss improved from 1.07379 to 1.05704, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_42.keras\n",
      "360/360 [==============================] - 27s 74ms/step - loss: 1.0444 - accuracy: 0.4617 - val_loss: 1.0570 - val_accuracy: 0.4503\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9586 - accuracy: 0.5385\n",
      "Epoch 3: val_loss did not improve from 1.05704\n",
      "360/360 [==============================] - 21s 57ms/step - loss: 0.9586 - accuracy: 0.5385 - val_loss: 1.1123 - val_accuracy: 0.4404\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8109 - accuracy: 0.6345\n",
      "Epoch 4: val_loss did not improve from 1.05704\n",
      "360/360 [==============================] - 16s 45ms/step - loss: 0.8109 - accuracy: 0.6345 - val_loss: 1.2457 - val_accuracy: 0.4358\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.7348\n",
      "Epoch 5: val_loss did not improve from 1.05704\n",
      "360/360 [==============================] - 13s 37ms/step - loss: 0.6259 - accuracy: 0.7348 - val_loss: 1.4661 - val_accuracy: 0.4188\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4631 - accuracy: 0.8133\n",
      "Epoch 6: val_loss did not improve from 1.05704\n",
      "360/360 [==============================] - 11s 31ms/step - loss: 0.4631 - accuracy: 0.8133 - val_loss: 1.8148 - val_accuracy: 0.4227\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.8657\n",
      "Epoch 7: val_loss did not improve from 1.05704\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 9s 25ms/step - loss: 0.3466 - accuracy: 0.8657 - val_loss: 2.0937 - val_accuracy: 0.4255\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 42): 141.17 seconds (2.35 minutes)\n",
      "[Seed 42] Val Loss: 1.0570 | Val Acc: 45.03%\n",
      "\n",
      "ðŸš€ Training new model for seed 119...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0874 - accuracy: 0.3910\n",
      "Epoch 1: val_loss improved from inf to 1.06984, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_119.keras\n",
      "360/360 [==============================] - 33s 83ms/step - loss: 1.0874 - accuracy: 0.3910 - val_loss: 1.0698 - val_accuracy: 0.4284\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0445 - accuracy: 0.4613\n",
      "Epoch 2: val_loss improved from 1.06984 to 1.05832, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_119.keras\n",
      "360/360 [==============================] - 21s 59ms/step - loss: 1.0445 - accuracy: 0.4613 - val_loss: 1.0583 - val_accuracy: 0.4495\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9645 - accuracy: 0.5326\n",
      "Epoch 3: val_loss did not improve from 1.05832\n",
      "360/360 [==============================] - 16s 45ms/step - loss: 0.9645 - accuracy: 0.5326 - val_loss: 1.1100 - val_accuracy: 0.4366\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8310 - accuracy: 0.6228\n",
      "Epoch 4: val_loss did not improve from 1.05832\n",
      "360/360 [==============================] - 14s 40ms/step - loss: 0.8310 - accuracy: 0.6228 - val_loss: 1.2077 - val_accuracy: 0.4376\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.7233\n",
      "Epoch 5: val_loss did not improve from 1.05832\n",
      "360/360 [==============================] - 13s 35ms/step - loss: 0.6492 - accuracy: 0.7233 - val_loss: 1.4708 - val_accuracy: 0.4156\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.8054\n",
      "Epoch 6: val_loss did not improve from 1.05832\n",
      "360/360 [==============================] - 10s 28ms/step - loss: 0.4838 - accuracy: 0.8054 - val_loss: 1.8647 - val_accuracy: 0.4113\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.8628\n",
      "Epoch 7: val_loss did not improve from 1.05832\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 9s 26ms/step - loss: 0.3552 - accuracy: 0.8628 - val_loss: 2.0393 - val_accuracy: 0.4140\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 119): 117.09 seconds (1.95 minutes)\n",
      "[Seed 119] Val Loss: 1.0583 | Val Acc: 44.95%\n",
      "\n",
      "ðŸš€ Training new model for seed 2020...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0877 - accuracy: 0.3898\n",
      "Epoch 1: val_loss improved from inf to 1.07063, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_2020.keras\n",
      "360/360 [==============================] - 33s 82ms/step - loss: 1.0877 - accuracy: 0.3898 - val_loss: 1.0706 - val_accuracy: 0.4351\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0463 - accuracy: 0.4577\n",
      "Epoch 2: val_loss improved from 1.07063 to 1.06180, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_2020.keras\n",
      "360/360 [==============================] - 21s 59ms/step - loss: 1.0463 - accuracy: 0.4577 - val_loss: 1.0618 - val_accuracy: 0.4483\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9547 - accuracy: 0.5437\n",
      "Epoch 3: val_loss did not improve from 1.06180\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.9547 - accuracy: 0.5437 - val_loss: 1.1207 - val_accuracy: 0.4425\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7950 - accuracy: 0.6484\n",
      "Epoch 4: val_loss did not improve from 1.06180\n",
      "360/360 [==============================] - 14s 38ms/step - loss: 0.7950 - accuracy: 0.6484 - val_loss: 1.2850 - val_accuracy: 0.4249\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5952 - accuracy: 0.7525\n",
      "Epoch 5: val_loss did not improve from 1.06180\n",
      "360/360 [==============================] - 11s 31ms/step - loss: 0.5952 - accuracy: 0.7525 - val_loss: 1.6055 - val_accuracy: 0.4167\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.8316\n",
      "Epoch 6: val_loss did not improve from 1.06180\n",
      "360/360 [==============================] - 10s 29ms/step - loss: 0.4251 - accuracy: 0.8316 - val_loss: 1.9385 - val_accuracy: 0.4155\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.8777\n",
      "Epoch 7: val_loss did not improve from 1.06180\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 10s 28ms/step - loss: 0.3156 - accuracy: 0.8777 - val_loss: 2.3273 - val_accuracy: 0.4143\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 2020): 114.84 seconds (1.91 minutes)\n",
      "[Seed 2020] Val Loss: 1.0618 | Val Acc: 44.83%\n",
      "\n",
      "ðŸš€ Training new model for seed 2024...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0862 - accuracy: 0.3949\n",
      "Epoch 1: val_loss improved from inf to 1.06605, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_2024.keras\n",
      "360/360 [==============================] - 32s 80ms/step - loss: 1.0862 - accuracy: 0.3949 - val_loss: 1.0660 - val_accuracy: 0.4376\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.4629\n",
      "Epoch 2: val_loss improved from 1.06605 to 1.06087, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_2024.keras\n",
      "360/360 [==============================] - 22s 60ms/step - loss: 1.0440 - accuracy: 0.4629 - val_loss: 1.0609 - val_accuracy: 0.4452\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9487 - accuracy: 0.5442\n",
      "Epoch 3: val_loss did not improve from 1.06087\n",
      "360/360 [==============================] - 17s 47ms/step - loss: 0.9487 - accuracy: 0.5442 - val_loss: 1.1357 - val_accuracy: 0.4375\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7834 - accuracy: 0.6494\n",
      "Epoch 4: val_loss did not improve from 1.06087\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 0.7834 - accuracy: 0.6494 - val_loss: 1.2927 - val_accuracy: 0.4224\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.7557\n",
      "Epoch 5: val_loss did not improve from 1.06087\n",
      "360/360 [==============================] - 11s 32ms/step - loss: 0.5859 - accuracy: 0.7557 - val_loss: 1.7263 - val_accuracy: 0.4187\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.8374\n",
      "Epoch 6: val_loss did not improve from 1.06087\n",
      "360/360 [==============================] - 9s 26ms/step - loss: 0.4140 - accuracy: 0.8374 - val_loss: 1.9710 - val_accuracy: 0.4206\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8816\n",
      "Epoch 7: val_loss did not improve from 1.06087\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 10s 27ms/step - loss: 0.3117 - accuracy: 0.8816 - val_loss: 2.1998 - val_accuracy: 0.4166\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 2024): 115.71 seconds (1.93 minutes)\n",
      "[Seed 2024] Val Loss: 1.0609 | Val Acc: 44.52%\n",
      "\n",
      "ðŸš€ Training new model for seed 2028...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0885 - accuracy: 0.3858\n",
      "Epoch 1: val_loss improved from inf to 1.07660, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_2028.keras\n",
      "360/360 [==============================] - 32s 80ms/step - loss: 1.0885 - accuracy: 0.3858 - val_loss: 1.0766 - val_accuracy: 0.4115\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0500 - accuracy: 0.4543\n",
      "Epoch 2: val_loss improved from 1.07660 to 1.06243, saving model to models_cnn_dual1_skip_drop/cnn_dual_seed_2028.keras\n",
      "360/360 [==============================] - 21s 59ms/step - loss: 1.0500 - accuracy: 0.4543 - val_loss: 1.0624 - val_accuracy: 0.4451\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9680 - accuracy: 0.5321\n",
      "Epoch 3: val_loss did not improve from 1.06243\n",
      "360/360 [==============================] - 17s 47ms/step - loss: 0.9680 - accuracy: 0.5321 - val_loss: 1.1096 - val_accuracy: 0.4460\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8236 - accuracy: 0.6280\n",
      "Epoch 4: val_loss did not improve from 1.06243\n",
      "360/360 [==============================] - 13s 37ms/step - loss: 0.8236 - accuracy: 0.6280 - val_loss: 1.2273 - val_accuracy: 0.4383\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6285 - accuracy: 0.7342\n",
      "Epoch 5: val_loss did not improve from 1.06243\n",
      "360/360 [==============================] - 12s 32ms/step - loss: 0.6285 - accuracy: 0.7342 - val_loss: 1.5626 - val_accuracy: 0.4299\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.8204\n",
      "Epoch 6: val_loss did not improve from 1.06243\n",
      "360/360 [==============================] - 10s 26ms/step - loss: 0.4552 - accuracy: 0.8204 - val_loss: 1.8663 - val_accuracy: 0.4165\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.8710\n",
      "Epoch 7: val_loss did not improve from 1.06243\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 9s 26ms/step - loss: 0.3395 - accuracy: 0.8710 - val_loss: 2.2231 - val_accuracy: 0.4147\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 2028): 113.94 seconds (1.90 minutes)\n",
      "[Seed 2028] Val Loss: 1.0624 | Val Acc: 44.51%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train one model or an ensemble over seeds\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "os.makedirs(\"models_cnn_dual1_skip_drop\", exist_ok=True)\n",
    "cnn_models = []\n",
    "\n",
    "for seed in CFG.seeds:\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    model_path = os.path.join(\"models_cnn_dual1_skip_drop\", f\"cnn_dual_seed_{seed}.keras\")\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"âœ… Found existing model for seed {seed}, loading...\")\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    else:\n",
    "        print(f\"ðŸš€ Training new model for seed {seed}...\")\n",
    "        model = get_dual_cnn_model(vocab_size=vocab_size, embed_dim=64, num_classes=3)\n",
    "\n",
    "        ckpt = ModelCheckpoint(\n",
    "            filepath=model_path,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        es = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # --- Measure training time ---\n",
    "        t0 = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=30,\n",
    "            callbacks=[ckpt, es],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print(f\"â±ï¸ CNN Training time (seed {seed}): {(t1 - t0):.2f} seconds ({(t1 - t0)/60:.2f} minutes)\")\n",
    "        \n",
    "        # --- Reload best model (for consistency) ---\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # --- Evaluate on validation set ---\n",
    "    loss, acc = model.evaluate(val_ds, verbose=0)\n",
    "    print(f\"[Seed {seed}] Val Loss: {loss:.4f} | Val Acc: {acc*100:.2f}%\\n\")\n",
    "\n",
    "    # --- Store model for ensemble ---\n",
    "    cnn_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56514fb-870a-4c61-b9b3-c764b67ebd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models in cnn_models: 5\n",
      "Model 0 predictions shape: (11496, 3)\n",
      "Model 1 predictions shape: (11496, 3)\n",
      "Model 2 predictions shape: (11496, 3)\n",
      "Model 3 predictions shape: (11496, 3)\n",
      "Model 4 predictions shape: (11496, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of models in cnn_models: {len(cnn_models)}\")\n",
    "if len(cnn_models) > 0:\n",
    "    for i, m in enumerate(cnn_models):\n",
    "        preds = m.predict(val_ds, verbose=0)\n",
    "        print(f\"Model {i} predictions shape:\", preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc2bc23-f8e5-4abb-b723-d8464a6806cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (CNN)\n",
    "y_proba_val_cnn = np.mean([m.predict(val_ds,  verbose=0) for m in cnn_models], axis=0)\n",
    "y_pred_val_cnn  = y_proba_val_cnn.argmax(axis=1)\n",
    "\n",
    "# Test predictions + submission\n",
    "test_ds = make_dual_dataset(test_pairs, labels=None, training=False)\n",
    "\n",
    "y_proba_test_cnn = np.mean([m.predict(test_ds, verbose=0) for m in cnn_models], axis=0)\n",
    "y_pred_test_cnn  = y_proba_test_cnn.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb9f0b37-b10a-4f5b-bfa2-6906fcdd2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CNN1-Skip EVALUATION ================\n",
      "\n",
      "*** GLOBAL METRICS ***\n",
      "Accuracy (Global)      : 0.4698\n",
      "Precision (Macro Avg)  : 0.4675\n",
      "Recall (Macro Avg)     : 0.4650\n",
      "F1-Score (Macro Avg)   : 0.4615\n",
      "\n",
      "*** PER-CLASS EVALUATION ***\n",
      "Class                Precision    Recall  F1-Score   Support\n",
      "------------------------------------------------------------\n",
      "winner_model_a            0.49      0.51      0.50      4013\n",
      "winner_model_b            0.46      0.56      0.51      3931\n",
      "winner_tie                0.45      0.33      0.38      3552\n",
      "------------------------------------------------------------\n",
      "Macro Avg                 0.47      0.46      0.46     34488\n",
      "Weighted Avg              0.47      0.47      0.46     34488\n",
      "\n",
      "*** ROC-AUC EVALUATION ***\n",
      "ROC-AUC (OvR) : 0.6376\n",
      "\n",
      "*** LOG-LOSS EVALUATION ***\n",
      "Log-loss      : 1.0443\n",
      "\n",
      "*** LOG-LOSS PER CLASS ***\n",
      "Class 0: 1.0461  (n=4013)\n",
      "Class 1: 0.9973  (n=3931)\n",
      "Class 2: 1.0942  (n=3552)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ CNN1-Skip EVALUATION ================\\n\")\n",
    "# Metrics\n",
    "_ = eval_metrics(y_val, y_pred_val_cnn)\n",
    "eval_classification_report(y_val, y_pred_val_cnn, class_names)\n",
    "# ROC-AUC\n",
    "_ = eval_roc_auc(y_val, y_proba_val_cnn)\n",
    "# Log-loss\n",
    "_ = eval_log_loss(y_val, y_proba_val_cnn)\n",
    "_ = eval_log_loss_per_class(y_val, y_proba_val_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880a1e6c-1a5b-436f-bed9-2f29d04433f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      " [[2031 1264  718]\n",
      " [1006 2207  718]\n",
      " [1075 1314 1163]]\n",
      "Saved plot to: images/confusion_matrix/confusion_matrix_cnn1s.png\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix + Plot\n",
    "cm_cnn = eval_confusion_matrix(y_val, y_pred_val_cnn, n_classes=y_proba_val_cnn.shape[1])\n",
    "plot_confusion_matrix(cm_cnn, class_names, title=\"Confusion Matrix â€” CNN1S\", save_path=\"results/confusion_matrix/confusion_matrix_cnn1s.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d4f7042-724d-48b0-9a67-9797aac5ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to: images/roc/roc_cnn1s.png\n"
     ]
    }
   ],
   "source": [
    "# ROC Curves\n",
    "plot_roc_curves(y_val, y_proba_val_cnn, class_names, title_prefix=\"CNN1S ROC\", save_path=\"results/roc/roc_cnn1s.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91e46aa-3068-40d2-89e9-46b1406caade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROC data for class 0 (AUC=0.6532) â†’ results/roc/CNN1S_fold1_class0.csv\n",
      "Saved ROC data for class 1 (AUC=0.6547) â†’ results/roc/CNN1S_fold1_class1.csv\n",
      "Saved ROC data for class 2 (AUC=0.6049) â†’ results/roc/CNN1S_fold1_class2.csv\n"
     ]
    }
   ],
   "source": [
    "save_roc_to_csv(y_val, y_proba_val_cnn, \"CNN1S\", fold_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb6dc0b-095c-47af-9c1e-4328cc34bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: results/submission/submission_cnn1s.csv\n"
     ]
    }
   ],
   "source": [
    "submission_cnn = build_submission(\n",
    "    test_df=test_df,\n",
    "    y_pred_test=y_pred_test_cnn,\n",
    "    y_proba_test=y_proba_test_cnn,\n",
    "    model_name=\"cnn1s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649f1bb-64aa-471b-87f8-253c4d98c253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
