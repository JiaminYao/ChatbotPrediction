{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a04504e-4021-45ae-8788-580d052d089c",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725c3f52-e1fb-4978-81ce-933f9c928358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 22:28:22.915963: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-02 22:28:22.916040: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-02 22:28:22.917852: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-02 22:28:22.928025: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import os, tensorflow as tf\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "from evaluation import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92942f37-3dbc-4623-aed3-d86bbd2debad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    TextVectorization, Embedding, Conv1D, GlobalMaxPooling1D,\n",
    "    Dense, Dropout, Input, MaxPooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d36760-c4a4-4fe8-95d5-169bdd75e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv A Example:\n",
      " What is a foreign exchange crisis? What are some notable examples?\n",
      "A foreign exchange crisis refers to a situation where a country faces severe shortage of foreign currencies, usually dollars or euros\n",
      "Conv B Example:\n",
      " What is a foreign exchange crisis? What are some notable examples?\n",
      "A foreign exchange crisis, also known as a currency crisis or balance of payments crisis, occurs when a country's currency experience\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "try:\n",
    "    CFG\n",
    "except NameError:\n",
    "    class CFG:\n",
    "        seeds = [42, 119, 2020, 2024, 2028]\n",
    "        \n",
    "train_df, test_df, y, class_names = load_and_prepare_data()\n",
    "pairs_train, pairs_val, test_pairs, y_train, y_val = prepare_dual_conversation_pipeline(train_df, test_df, y)\n",
    "\n",
    "print(\"Conv A Example:\\n\", pairs_train[0][0][:200])\n",
    "print(\"Conv B Example:\\n\", pairs_train[0][1][:200])\n",
    "print(\"Label:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2742a2d4-9703-4121-b587-90d0c16518f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 22:28:38.483226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38367 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer (shared across the two inputs)\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vocab_size = 20000\n",
    "max_length = 512\n",
    "\n",
    "adapt_strings = [p[0] for p in pairs_train] + [p[1] for p in pairs_train]\n",
    "adapt_ds = tf.data.Dataset.from_tensor_slices([str(t) for t in adapt_strings]).batch(1024)\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "text_vectorizer.adapt(adapt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473d51b2-47dd-41c2-8710-ae061016ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data pipelines for ((A,B), y)\n",
    "def make_dual_dataset(pairs, labels=None, batch_size=128, training=True):\n",
    "    part_a = [str(p[0]) for p in pairs]\n",
    "    part_b = [str(p[1]) for p in pairs]\n",
    "\n",
    "    inputs = {\"inp_a\": tf.constant(part_a), \"inp_b\": tf.constant(part_b)}\n",
    "\n",
    "    if labels is None:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    else:\n",
    "        labels = np.asarray(labels, dtype=np.int32)\n",
    "        ds = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "\n",
    "    if labels is not None and training:\n",
    "        ds = ds.shuffle(2048, reshuffle_each_iteration=True)\n",
    "\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_dual_dataset(pairs_train, y_train, training=True)\n",
    "val_ds   = make_dual_dataset(pairs_val,   y_val,   training=False)\n",
    "test_ds  = make_dual_dataset(test_pairs,  labels=None,  training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62a1b71-9c02-4b24-8b25-c79cec2bdac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (two string inputs â†’ vectorizer â†’ shared embedding â†’ concat â†’ conv)\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, MaxPooling1D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_dual_cnn_model(vocab_size=vocab_size, embed_dim=64, num_classes=3):\n",
    "    inp_a = Input(shape=(), dtype=tf.string, name=\"inp_a\")\n",
    "    inp_b = Input(shape=(), dtype=tf.string, name=\"inp_b\")\n",
    "\n",
    "    # shared layers\n",
    "    emb   = Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
    "\n",
    "    # branch A\n",
    "    xa = text_vectorizer(inp_a)\n",
    "    xa = emb(xa)\n",
    "    xa = Conv1D(32, 3, activation=\"relu\")(xa)\n",
    "    xa = Conv1D(32, 3, activation=\"relu\")(xa)\n",
    "    xa = MaxPooling1D()(xa)\n",
    "    xa = Conv1D(64, 3, activation=\"relu\")(xa)\n",
    "    xa = Conv1D(64, 3, activation=\"relu\")(xa)\n",
    "    xa = MaxPooling1D()(xa)\n",
    "    xa = Conv1D(128, 3, activation=\"relu\")(xa)\n",
    "    xa = GlobalMaxPooling1D()(xa)\n",
    "\n",
    "    # branch B\n",
    "    xb = text_vectorizer(inp_b)\n",
    "    xb = emb(xb)\n",
    "    xb = Conv1D(32, 3, activation=\"relu\")(xb)\n",
    "    xb = Conv1D(32, 3, activation=\"relu\")(xb)\n",
    "    xb = MaxPooling1D()(xb)\n",
    "    xb = Conv1D(64, 3, activation=\"relu\")(xb)\n",
    "    xb = Conv1D(64, 3, activation=\"relu\")(xb)\n",
    "    xb = MaxPooling1D()(xb)\n",
    "    xb = Conv1D(128, 3, activation=\"relu\")(xb)\n",
    "    xb = GlobalMaxPooling1D()(xb)\n",
    "\n",
    "    # merge\n",
    "    x  = Concatenate()([xa, xb])\n",
    "    x  = Dropout(0.3)(x)\n",
    "    x  = Dense(256, activation=\"swish\")(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=[inp_a, inp_b], outputs=out)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da7f1d1-23be-41a0-9f7b-4c4c61bcc7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training new model for seed 42...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 22:28:46.695367: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-11-02 22:28:47.170244: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-11-02 22:28:47.257746: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-11-02 22:28:48.348094: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ffcf0525db0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-02 22:28:48.348130: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2025-11-02 22:28:48.354461: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762144128.435576 2565815 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - ETA: 0s - loss: 1.0942 - accuracy: 0.3665\n",
      "Epoch 1: val_loss improved from inf to 1.09748, saving model to models_cnn_dual2/cnn_dual_seed_42.keras\n",
      "360/360 [==============================] - 45s 109ms/step - loss: 1.0942 - accuracy: 0.3665 - val_loss: 1.0975 - val_accuracy: 0.3781\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0569 - accuracy: 0.4433\n",
      "Epoch 2: val_loss improved from 1.09748 to 1.09699, saving model to models_cnn_dual2/cnn_dual_seed_42.keras\n",
      "360/360 [==============================] - 29s 80ms/step - loss: 1.0569 - accuracy: 0.4433 - val_loss: 1.0970 - val_accuracy: 0.4217\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9419 - accuracy: 0.5520\n",
      "Epoch 3: val_loss did not improve from 1.09699\n",
      "360/360 [==============================] - 20s 54ms/step - loss: 0.9419 - accuracy: 0.5520 - val_loss: 1.2899 - val_accuracy: 0.4050\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7713 - accuracy: 0.6577\n",
      "Epoch 4: val_loss did not improve from 1.09699\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.7713 - accuracy: 0.6577 - val_loss: 1.5847 - val_accuracy: 0.3914\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6252 - accuracy: 0.7313\n",
      "Epoch 5: val_loss did not improve from 1.09699\n",
      "360/360 [==============================] - 13s 36ms/step - loss: 0.6252 - accuracy: 0.7313 - val_loss: 1.7083 - val_accuracy: 0.3820\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5191 - accuracy: 0.7852\n",
      "Epoch 6: val_loss did not improve from 1.09699\n",
      "360/360 [==============================] - 12s 33ms/step - loss: 0.5191 - accuracy: 0.7852 - val_loss: 1.9257 - val_accuracy: 0.3856\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.8189\n",
      "Epoch 7: val_loss did not improve from 1.09699\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 11s 29ms/step - loss: 0.4384 - accuracy: 0.8189 - val_loss: 2.3771 - val_accuracy: 0.3835\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 42): 144.10 seconds (2.40 minutes)\n",
      "[Seed 42] Val Loss: 1.0970 | Val Acc: 42.17%\n",
      "\n",
      "ðŸš€ Training new model for seed 119...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0946 - accuracy: 0.3667\n",
      "Epoch 1: val_loss improved from inf to 1.08312, saving model to models_cnn_dual2/cnn_dual_seed_119.keras\n",
      "360/360 [==============================] - 32s 82ms/step - loss: 1.0946 - accuracy: 0.3667 - val_loss: 1.0831 - val_accuracy: 0.4041\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0489 - accuracy: 0.4549\n",
      "Epoch 2: val_loss did not improve from 1.08312\n",
      "360/360 [==============================] - 22s 60ms/step - loss: 1.0489 - accuracy: 0.4549 - val_loss: 1.1155 - val_accuracy: 0.4055\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9040 - accuracy: 0.5745\n",
      "Epoch 3: val_loss did not improve from 1.08312\n",
      "360/360 [==============================] - 17s 47ms/step - loss: 0.9040 - accuracy: 0.5745 - val_loss: 1.3240 - val_accuracy: 0.4121\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7276 - accuracy: 0.6789\n",
      "Epoch 4: val_loss did not improve from 1.08312\n",
      "360/360 [==============================] - 15s 42ms/step - loss: 0.7276 - accuracy: 0.6789 - val_loss: 1.5458 - val_accuracy: 0.3952\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.7532\n",
      "Epoch 5: val_loss did not improve from 1.08312\n",
      "360/360 [==============================] - 12s 34ms/step - loss: 0.5817 - accuracy: 0.7532 - val_loss: 1.8668 - val_accuracy: 0.3753\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.7997\n",
      "Epoch 6: val_loss did not improve from 1.08312\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 9s 26ms/step - loss: 0.4836 - accuracy: 0.7997 - val_loss: 1.9476 - val_accuracy: 0.3886\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 119): 107.76 seconds (1.80 minutes)\n",
      "[Seed 119] Val Loss: 1.0831 | Val Acc: 40.41%\n",
      "\n",
      "ðŸš€ Training new model for seed 2020...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0954 - accuracy: 0.3614\n",
      "Epoch 1: val_loss improved from inf to 1.09028, saving model to models_cnn_dual2/cnn_dual_seed_2020.keras\n",
      "360/360 [==============================] - 31s 80ms/step - loss: 1.0954 - accuracy: 0.3614 - val_loss: 1.0903 - val_accuracy: 0.3872\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0703 - accuracy: 0.4216\n",
      "Epoch 2: val_loss did not improve from 1.09028\n",
      "360/360 [==============================] - 20s 56ms/step - loss: 1.0703 - accuracy: 0.4216 - val_loss: 1.1150 - val_accuracy: 0.4033\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9804 - accuracy: 0.5175\n",
      "Epoch 3: val_loss did not improve from 1.09028\n",
      "360/360 [==============================] - 18s 50ms/step - loss: 0.9804 - accuracy: 0.5175 - val_loss: 1.1741 - val_accuracy: 0.4027\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8210 - accuracy: 0.6220\n",
      "Epoch 4: val_loss did not improve from 1.09028\n",
      "360/360 [==============================] - 15s 42ms/step - loss: 0.8210 - accuracy: 0.6220 - val_loss: 1.3709 - val_accuracy: 0.3872\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.7034\n",
      "Epoch 5: val_loss did not improve from 1.09028\n",
      "360/360 [==============================] - 12s 34ms/step - loss: 0.6698 - accuracy: 0.7034 - val_loss: 1.6240 - val_accuracy: 0.3878\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5545 - accuracy: 0.7605\n",
      "Epoch 6: val_loss did not improve from 1.09028\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 10s 28ms/step - loss: 0.5545 - accuracy: 0.7605 - val_loss: 1.8242 - val_accuracy: 0.3829\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 2020): 106.95 seconds (1.78 minutes)\n",
      "[Seed 2020] Val Loss: 1.0903 | Val Acc: 38.72%\n",
      "\n",
      "ðŸš€ Training new model for seed 2024...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0937 - accuracy: 0.3690\n",
      "Epoch 1: val_loss improved from inf to 1.08292, saving model to models_cnn_dual2/cnn_dual_seed_2024.keras\n",
      "360/360 [==============================] - 31s 80ms/step - loss: 1.0937 - accuracy: 0.3690 - val_loss: 1.0829 - val_accuracy: 0.4043\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0438 - accuracy: 0.4625\n",
      "Epoch 2: val_loss did not improve from 1.08292\n",
      "360/360 [==============================] - 21s 60ms/step - loss: 1.0438 - accuracy: 0.4625 - val_loss: 1.0963 - val_accuracy: 0.4140\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8853 - accuracy: 0.5866\n",
      "Epoch 3: val_loss did not improve from 1.08292\n",
      "360/360 [==============================] - 16s 46ms/step - loss: 0.8853 - accuracy: 0.5866 - val_loss: 1.3644 - val_accuracy: 0.4098\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6928 - accuracy: 0.6958\n",
      "Epoch 4: val_loss did not improve from 1.08292\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 0.6928 - accuracy: 0.6958 - val_loss: 1.7792 - val_accuracy: 0.3991\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.7657\n",
      "Epoch 5: val_loss did not improve from 1.08292\n",
      "360/360 [==============================] - 11s 31ms/step - loss: 0.5524 - accuracy: 0.7657 - val_loss: 1.9771 - val_accuracy: 0.3893\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.8091\n",
      "Epoch 6: val_loss did not improve from 1.08292\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 12s 35ms/step - loss: 0.4618 - accuracy: 0.8091 - val_loss: 2.3053 - val_accuracy: 0.3886\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 2024): 106.70 seconds (1.78 minutes)\n",
      "[Seed 2024] Val Loss: 1.0829 | Val Acc: 40.43%\n",
      "\n",
      "ðŸš€ Training new model for seed 2028...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0950 - accuracy: 0.3626\n",
      "Epoch 1: val_loss improved from inf to 1.08509, saving model to models_cnn_dual2/cnn_dual_seed_2028.keras\n",
      "360/360 [==============================] - 32s 81ms/step - loss: 1.0950 - accuracy: 0.3626 - val_loss: 1.0851 - val_accuracy: 0.4092\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0579 - accuracy: 0.4416\n",
      "Epoch 2: val_loss did not improve from 1.08509\n",
      "360/360 [==============================] - 21s 57ms/step - loss: 1.0579 - accuracy: 0.4416 - val_loss: 1.1020 - val_accuracy: 0.4056\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9208 - accuracy: 0.5656\n",
      "Epoch 3: val_loss did not improve from 1.08509\n",
      "360/360 [==============================] - 17s 46ms/step - loss: 0.9208 - accuracy: 0.5656 - val_loss: 1.2405 - val_accuracy: 0.3795\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.6721\n",
      "Epoch 4: val_loss did not improve from 1.08509\n",
      "360/360 [==============================] - 14s 38ms/step - loss: 0.7397 - accuracy: 0.6721 - val_loss: 1.5142 - val_accuracy: 0.3862\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.7507\n",
      "Epoch 5: val_loss did not improve from 1.08509\n",
      "360/360 [==============================] - 12s 34ms/step - loss: 0.5890 - accuracy: 0.7507 - val_loss: 1.8335 - val_accuracy: 0.3791\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4939 - accuracy: 0.7968\n",
      "Epoch 6: val_loss did not improve from 1.08509\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 12s 33ms/step - loss: 0.4939 - accuracy: 0.7968 - val_loss: 2.1378 - val_accuracy: 0.3767\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 2028): 106.95 seconds (1.78 minutes)\n",
      "[Seed 2028] Val Loss: 1.0851 | Val Acc: 40.92%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train one model or an ensemble over seeds\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "os.makedirs(\"models_cnn_dual2\", exist_ok=True)\n",
    "cnn_models = []\n",
    "\n",
    "for seed in CFG.seeds:\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    model_path = os.path.join(\"models_cnn_dual2\", f\"cnn_dual_seed_{seed}.keras\")\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"âœ… Found existing model for seed {seed}, loading...\")\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    else:\n",
    "        print(f\"ðŸš€ Training new model for seed {seed}...\")\n",
    "        model = get_dual_cnn_model(vocab_size=vocab_size, embed_dim=64, num_classes=3)\n",
    "\n",
    "        ckpt = ModelCheckpoint(\n",
    "            filepath=model_path,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        es = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # --- Measure training time ---\n",
    "        t0 = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=30,\n",
    "            callbacks=[ckpt, es],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print(f\"â±ï¸ CNN Training time (seed {seed}): {(t1 - t0):.2f} seconds ({(t1 - t0)/60:.2f} minutes)\")\n",
    "        \n",
    "        # --- Reload best model (for consistency) ---\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # --- Evaluate on validation set ---\n",
    "    loss, acc = model.evaluate(val_ds, verbose=0)\n",
    "    print(f\"[Seed {seed}] Val Loss: {loss:.4f} | Val Acc: {acc*100:.2f}%\\n\")\n",
    "\n",
    "    # --- Store model for ensemble ---\n",
    "    cnn_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56514fb-870a-4c61-b9b3-c764b67ebd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models in cnn_models: 5\n",
      "Model 0 predictions shape: (11496, 3)\n",
      "Model 1 predictions shape: (11496, 3)\n",
      "Model 2 predictions shape: (11496, 3)\n",
      "Model 3 predictions shape: (11496, 3)\n",
      "Model 4 predictions shape: (11496, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of models in cnn_models: {len(cnn_models)}\")\n",
    "if len(cnn_models) > 0:\n",
    "    for i, m in enumerate(cnn_models):\n",
    "        preds = m.predict(val_ds, verbose=0)\n",
    "        print(f\"Model {i} predictions shape:\", preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc2bc23-f8e5-4abb-b723-d8464a6806cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (CNN)\n",
    "y_proba_val_cnn = np.mean([m.predict(val_ds,  verbose=0) for m in cnn_models], axis=0)\n",
    "y_pred_val_cnn  = y_proba_val_cnn.argmax(axis=1)\n",
    "\n",
    "# Test predictions + submission\n",
    "test_ds = make_dual_dataset(test_pairs, labels=None, training=False)\n",
    "\n",
    "y_proba_test_cnn = np.mean([m.predict(test_ds, verbose=0) for m in cnn_models], axis=0)\n",
    "y_pred_test_cnn  = y_proba_test_cnn.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb9f0b37-b10a-4f5b-bfa2-6906fcdd2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CNN2 EVALUATION ================\n",
      "\n",
      "*** GLOBAL METRICS ***\n",
      "Accuracy (Global)      : 0.4323\n",
      "Precision (Macro Avg)  : 0.4375\n",
      "Recall (Macro Avg)     : 0.4252\n",
      "F1-Score (Macro Avg)   : 0.4166\n",
      "\n",
      "*** PER-CLASS EVALUATION ***\n",
      "Class                Precision    Recall  F1-Score   Support\n",
      "------------------------------------------------------------\n",
      "winner_model_a            0.42      0.57      0.48      4013\n",
      "winner_model_b            0.44      0.46      0.45      3931\n",
      "winner_tie                0.45      0.24      0.31      3552\n",
      "------------------------------------------------------------\n",
      "Macro Avg                 0.44      0.43      0.42     34488\n",
      "Weighted Avg              0.44      0.43      0.42     34488\n",
      "\n",
      "*** ROC-AUC EVALUATION ***\n",
      "ROC-AUC (OvR) : 0.6003\n",
      "\n",
      "*** LOG-LOSS EVALUATION ***\n",
      "Log-loss      : 1.0750\n",
      "\n",
      "*** LOG-LOSS PER CLASS ***\n",
      "Class 0: 1.0170  (n=4013)\n",
      "Class 1: 1.0449  (n=3931)\n",
      "Class 2: 1.1738  (n=3552)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ CNN2 EVALUATION ================\\n\")\n",
    "# Metrics\n",
    "_ = eval_metrics(y_val, y_pred_val_cnn)\n",
    "eval_classification_report(y_val, y_pred_val_cnn, class_names)\n",
    "# ROC-AUC\n",
    "_ = eval_roc_auc(y_val, y_proba_val_cnn)\n",
    "# Log-loss\n",
    "_ = eval_log_loss(y_val, y_proba_val_cnn)\n",
    "_ = eval_log_loss_per_class(y_val, y_proba_val_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880a1e6c-1a5b-436f-bed9-2f29d04433f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      " [[2288 1223  502]\n",
      " [1574 1827  530]\n",
      " [1596 1101  855]]\n",
      "Saved plot to: images/confusion_matrix/confusion_matrix_cnn2.png\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix + Plot\n",
    "cm_cnn = eval_confusion_matrix(y_val, y_pred_val_cnn, n_classes=y_proba_val_cnn.shape[1])\n",
    "plot_confusion_matrix(cm_cnn, class_names, title=\"Confusion Matrix â€” CNN2\", save_path=\"results/confusion_matrix/confusion_matrix_cnn2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d4f7042-724d-48b0-9a67-9797aac5ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to: images/roc/roc_cnn2.png\n"
     ]
    }
   ],
   "source": [
    "# ROC Curves\n",
    "plot_roc_curves(y_val, y_proba_val_cnn, class_names, title_prefix=\"CNN2 ROC\", save_path=\"results/roc/roc_cnn2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91e46aa-3068-40d2-89e9-46b1406caade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROC data for class 0 (AUC=0.6100) â†’ results/roc/CNN2_fold1_class0.csv\n",
      "Saved ROC data for class 1 (AUC=0.6129) â†’ results/roc/CNN2_fold1_class1.csv\n",
      "Saved ROC data for class 2 (AUC=0.5782) â†’ results/roc/CNN2_fold1_class2.csv\n"
     ]
    }
   ],
   "source": [
    "save_roc_to_csv(y_val, y_proba_val_cnn, \"CNN2\", fold_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb6dc0b-095c-47af-9c1e-4328cc34bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: results/submission/submission_cnn2.csv\n"
     ]
    }
   ],
   "source": [
    "submission_cnn = build_submission(\n",
    "    test_df=test_df,\n",
    "    y_pred_test=y_pred_test_cnn,\n",
    "    y_proba_test=y_proba_test_cnn,\n",
    "    model_name=\"cnn2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649f1bb-64aa-471b-87f8-253c4d98c253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
