{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a04504e-4021-45ae-8788-580d052d089c",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725c3f52-e1fb-4978-81ce-933f9c928358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 10:02:08.758576: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-16 10:02:08.758651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-16 10:02:08.768926: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-16 10:02:08.809886: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import os, tensorflow as tf\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "from evaluation import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92942f37-3dbc-4623-aed3-d86bbd2debad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    TextVectorization, Embedding, Conv1D, GlobalMaxPooling1D,\n",
    "    Dense, Dropout, Input, MaxPooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d36760-c4a4-4fe8-95d5-169bdd75e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv A Example:\n",
      " What is a foreign exchange crisis? What are some notable examples?\n",
      "A foreign exchange crisis refers to a situation where a country faces severe shortage of foreign currencies, usually dollars or euros\n",
      "Conv B Example:\n",
      " What is a foreign exchange crisis? What are some notable examples?\n",
      "A foreign exchange crisis, also known as a currency crisis or balance of payments crisis, occurs when a country's currency experience\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "try:\n",
    "    CFG\n",
    "except NameError:\n",
    "    class CFG:\n",
    "        seeds = [42, 119, 2020, 2024, 2028]\n",
    "        \n",
    "train_df, test_df, y, class_names = load_and_prepare_data()\n",
    "pairs_train, pairs_val, test_pairs, y_train, y_val = prepare_dual_conversation_pipeline(train_df, test_df, y)\n",
    "\n",
    "print(\"Conv A Example:\\n\", pairs_train[0][0][:200])\n",
    "print(\"Conv B Example:\\n\", pairs_train[0][1][:200])\n",
    "print(\"Label:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2742a2d4-9703-4121-b587-90d0c16518f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 10:02:28.275708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38367 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0\n",
      "2025-11-16 10:02:28.278133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38367 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer (shared across the two inputs)\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vocab_size = 20000\n",
    "max_length = 512\n",
    "\n",
    "adapt_strings = [p[0] for p in pairs_train] + [p[1] for p in pairs_train]\n",
    "adapt_ds = tf.data.Dataset.from_tensor_slices([str(t) for t in adapt_strings]).batch(1024)\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "text_vectorizer.adapt(adapt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473d51b2-47dd-41c2-8710-ae061016ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data pipelines for ((A,B), y)\n",
    "def make_dual_dataset(pairs, labels=None, batch_size=128, training=True):\n",
    "    part_a = [str(p[0]) for p in pairs]\n",
    "    part_b = [str(p[1]) for p in pairs]\n",
    "\n",
    "    inputs = {\"inp_a\": tf.constant(part_a), \"inp_b\": tf.constant(part_b)}\n",
    "\n",
    "    if labels is None:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    else:\n",
    "        labels = np.asarray(labels, dtype=np.int32)\n",
    "        ds = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "\n",
    "    if labels is not None and training:\n",
    "        ds = ds.shuffle(2048, reshuffle_each_iteration=True)\n",
    "\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_dual_dataset(pairs_train, y_train, training=True)\n",
    "val_ds   = make_dual_dataset(pairs_val,   y_val,   training=False)\n",
    "test_ds  = make_dual_dataset(test_pairs,  labels=None,  training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62a1b71-9c02-4b24-8b25-c79cec2bdac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (two string inputs â†’ vectorizer â†’ shared embedding â†’ concat â†’ conv)\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, MaxPooling1D, Concatenate, Add\n",
    "\n",
    "def res_block(x, filters, use_projection=False):\n",
    "    shortcut = x\n",
    "    out = Conv1D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    out = Conv1D(filters, 3, padding=\"same\")(out)\n",
    "\n",
    "    if use_projection or shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding=\"same\")(shortcut)\n",
    "\n",
    "    out = Add()([out, shortcut])\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "    \n",
    "def conv_block(x, filters, use_residual=False, pool=True):\n",
    "    if use_residual:\n",
    "        x = res_block(x, filters, use_projection=True)\n",
    "    else:\n",
    "        x = Conv1D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    if pool:\n",
    "        x = MaxPooling1D()(x)\n",
    "    return x\n",
    "\n",
    "def get_dual_cnn_model(vocab_size=vocab_size, embed_dim=64, num_classes=3):\n",
    "    inp_a = Input(shape=(), dtype=tf.string, name=\"inp_a\")\n",
    "    inp_b = Input(shape=(), dtype=tf.string, name=\"inp_b\")\n",
    "\n",
    "    # shared layers\n",
    "    emb   = Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
    "\n",
    "    # branch A\n",
    "    xa = text_vectorizer(inp_a)\n",
    "    xa = emb(xa)\n",
    "    \n",
    "    # Conv32Ã—2 â†’ MP\n",
    "    xa = conv_block(xa, 32, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv64Ã—2 â†’ MP\n",
    "    xa = conv_block(xa, 64, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv128Ã—2 â†’ MP\n",
    "    xa = conv_block(xa, 128, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv256Ã—2 â†’ GMP\n",
    "    xa = conv_block(xa, 256, use_residual=True, pool=False)\n",
    "    xa = GlobalMaxPooling1D()(xa)\n",
    "\n",
    "    # branch B\n",
    "    xb = text_vectorizer(inp_b)\n",
    "    xb = emb(xb)\n",
    "\n",
    "    # Conv32Ã—2 â†’ MP\n",
    "    xb = conv_block(xb, 32, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv64Ã—2 â†’ MP\n",
    "    xb = conv_block(xb, 64, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv128Ã—2 â†’ MP\n",
    "    xb = conv_block(xb, 128, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv256Ã—2 â†’ GMP\n",
    "    xb = conv_block(xb, 256, use_residual=True, pool=False)\n",
    "    xb = GlobalMaxPooling1D()(xb)\n",
    "    \n",
    "    # merge\n",
    "    x  = Concatenate()([xa, xb])\n",
    "    x  = Dropout(0.3)(x)\n",
    "    x  = Dense(512, activation=\"swish\")(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=[inp_a, inp_b], outputs=out)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da7f1d1-23be-41a0-9f7b-4c4c61bcc7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training new model for seed 42...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 10:02:37.534376: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-11-16 10:02:38.043915: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-11-16 10:02:38.127460: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-11-16 10:02:39.672580: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ffccf7870c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-16 10:02:39.672620: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2025-11-16 10:02:39.672625: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2025-11-16 10:02:39.678752: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763308959.753878 2318951 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - ETA: 0s - loss: 1.0958 - accuracy: 0.3594\n",
      "Epoch 1: val_loss improved from inf to 1.09090, saving model to models_cnn_dual5_skip/cnn_dual_seed_42.keras\n",
      "360/360 [==============================] - 49s 111ms/step - loss: 1.0958 - accuracy: 0.3594 - val_loss: 1.0909 - val_accuracy: 0.3981\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0798 - accuracy: 0.4149\n",
      "Epoch 2: val_loss improved from 1.09090 to 1.08130, saving model to models_cnn_dual5_skip/cnn_dual_seed_42.keras\n",
      "360/360 [==============================] - 29s 81ms/step - loss: 1.0798 - accuracy: 0.4149 - val_loss: 1.0813 - val_accuracy: 0.4113\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0078 - accuracy: 0.4952\n",
      "Epoch 3: val_loss did not improve from 1.08130\n",
      "360/360 [==============================] - 21s 57ms/step - loss: 1.0078 - accuracy: 0.4952 - val_loss: 1.1346 - val_accuracy: 0.4041\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8508 - accuracy: 0.6073\n",
      "Epoch 4: val_loss did not improve from 1.08130\n",
      "360/360 [==============================] - 17s 47ms/step - loss: 0.8508 - accuracy: 0.6073 - val_loss: 1.3183 - val_accuracy: 0.3888\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6839 - accuracy: 0.7035\n",
      "Epoch 5: val_loss did not improve from 1.08130\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 0.6839 - accuracy: 0.7035 - val_loss: 1.5630 - val_accuracy: 0.3889\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5466 - accuracy: 0.7729\n",
      "Epoch 6: val_loss did not improve from 1.08130\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 0.5466 - accuracy: 0.7729 - val_loss: 1.9080 - val_accuracy: 0.3885\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.8195\n",
      "Epoch 7: val_loss did not improve from 1.08130\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 11s 31ms/step - loss: 0.4396 - accuracy: 0.8195 - val_loss: 2.1959 - val_accuracy: 0.3702\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 42): 155.03 seconds (2.58 minutes)\n",
      "[Seed 42] Val Loss: 1.0813 | Val Acc: 41.13%\n",
      "\n",
      "ðŸš€ Training new model for seed 119...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0961 - accuracy: 0.3603\n",
      "Epoch 1: val_loss improved from inf to 1.09051, saving model to models_cnn_dual5_skip/cnn_dual_seed_119.keras\n",
      "360/360 [==============================] - 37s 87ms/step - loss: 1.0961 - accuracy: 0.3603 - val_loss: 1.0905 - val_accuracy: 0.3950\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0806 - accuracy: 0.4068\n",
      "Epoch 2: val_loss did not improve from 1.09051\n",
      "360/360 [==============================] - 23s 64ms/step - loss: 1.0806 - accuracy: 0.4068 - val_loss: 1.0942 - val_accuracy: 0.3892\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0141 - accuracy: 0.4855\n",
      "Epoch 3: val_loss did not improve from 1.09051\n",
      "360/360 [==============================] - 19s 53ms/step - loss: 1.0141 - accuracy: 0.4855 - val_loss: 1.1578 - val_accuracy: 0.3922\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8697 - accuracy: 0.5947\n",
      "Epoch 4: val_loss did not improve from 1.09051\n",
      "360/360 [==============================] - 15s 43ms/step - loss: 0.8697 - accuracy: 0.5947 - val_loss: 1.3867 - val_accuracy: 0.3696\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.6897\n",
      "Epoch 5: val_loss did not improve from 1.09051\n",
      "360/360 [==============================] - 14s 39ms/step - loss: 0.7060 - accuracy: 0.6897 - val_loss: 1.6434 - val_accuracy: 0.3747\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5654 - accuracy: 0.7638\n",
      "Epoch 6: val_loss did not improve from 1.09051\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 11s 31ms/step - loss: 0.5654 - accuracy: 0.7638 - val_loss: 1.9273 - val_accuracy: 0.3740\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 119): 119.50 seconds (1.99 minutes)\n",
      "[Seed 119] Val Loss: 1.0905 | Val Acc: 39.50%\n",
      "\n",
      "ðŸš€ Training new model for seed 2020...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0950 - accuracy: 0.3666\n",
      "Epoch 1: val_loss improved from inf to 1.08682, saving model to models_cnn_dual5_skip/cnn_dual_seed_2020.keras\n",
      "360/360 [==============================] - 37s 87ms/step - loss: 1.0950 - accuracy: 0.3666 - val_loss: 1.0868 - val_accuracy: 0.4052\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0731 - accuracy: 0.4280\n",
      "Epoch 2: val_loss did not improve from 1.08682\n",
      "360/360 [==============================] - 22s 61ms/step - loss: 1.0731 - accuracy: 0.4280 - val_loss: 1.0928 - val_accuracy: 0.4011\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9890 - accuracy: 0.5116\n",
      "Epoch 3: val_loss did not improve from 1.08682\n",
      "360/360 [==============================] - 18s 51ms/step - loss: 0.9890 - accuracy: 0.5116 - val_loss: 1.1437 - val_accuracy: 0.3955\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8295 - accuracy: 0.6214\n",
      "Epoch 4: val_loss did not improve from 1.08682\n",
      "360/360 [==============================] - 15s 43ms/step - loss: 0.8295 - accuracy: 0.6214 - val_loss: 1.3261 - val_accuracy: 0.3995\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.7151\n",
      "Epoch 5: val_loss did not improve from 1.08682\n",
      "360/360 [==============================] - 14s 38ms/step - loss: 0.6590 - accuracy: 0.7151 - val_loss: 1.5453 - val_accuracy: 0.3856\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.7857\n",
      "Epoch 6: val_loss did not improve from 1.08682\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 12s 33ms/step - loss: 0.5232 - accuracy: 0.7857 - val_loss: 1.9978 - val_accuracy: 0.3807\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 2020): 118.06 seconds (1.97 minutes)\n",
      "[Seed 2020] Val Loss: 1.0868 | Val Acc: 40.52%\n",
      "\n",
      "ðŸš€ Training new model for seed 2024...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0967 - accuracy: 0.3514\n",
      "Epoch 1: val_loss improved from inf to 1.09276, saving model to models_cnn_dual5_skip/cnn_dual_seed_2024.keras\n",
      "360/360 [==============================] - 37s 87ms/step - loss: 1.0967 - accuracy: 0.3514 - val_loss: 1.0928 - val_accuracy: 0.3674\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0867 - accuracy: 0.3883\n",
      "Epoch 2: val_loss did not improve from 1.09276\n",
      "360/360 [==============================] - 24s 66ms/step - loss: 1.0867 - accuracy: 0.3883 - val_loss: 1.0931 - val_accuracy: 0.3787\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0468 - accuracy: 0.4496\n",
      "Epoch 3: val_loss did not improve from 1.09276\n",
      "360/360 [==============================] - 18s 51ms/step - loss: 1.0468 - accuracy: 0.4496 - val_loss: 1.1448 - val_accuracy: 0.3919\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9457 - accuracy: 0.5377\n",
      "Epoch 4: val_loss did not improve from 1.09276\n",
      "360/360 [==============================] - 16s 44ms/step - loss: 0.9457 - accuracy: 0.5377 - val_loss: 1.2921 - val_accuracy: 0.3940\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7943 - accuracy: 0.6361\n",
      "Epoch 5: val_loss did not improve from 1.09276\n",
      "360/360 [==============================] - 12s 35ms/step - loss: 0.7943 - accuracy: 0.6361 - val_loss: 1.4732 - val_accuracy: 0.3814\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.7146\n",
      "Epoch 6: val_loss did not improve from 1.09276\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 11s 32ms/step - loss: 0.6505 - accuracy: 0.7146 - val_loss: 1.6852 - val_accuracy: 0.3767\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 2024): 118.27 seconds (1.97 minutes)\n",
      "[Seed 2024] Val Loss: 1.0928 | Val Acc: 36.74%\n",
      "\n",
      "ðŸš€ Training new model for seed 2028...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0958 - accuracy: 0.3621\n",
      "Epoch 1: val_loss improved from inf to 1.09068, saving model to models_cnn_dual5_skip/cnn_dual_seed_2028.keras\n",
      "360/360 [==============================] - 38s 89ms/step - loss: 1.0958 - accuracy: 0.3621 - val_loss: 1.0907 - val_accuracy: 0.3889\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0804 - accuracy: 0.4108\n",
      "Epoch 2: val_loss improved from 1.09068 to 1.08983, saving model to models_cnn_dual5_skip/cnn_dual_seed_2028.keras\n",
      "360/360 [==============================] - 22s 62ms/step - loss: 1.0804 - accuracy: 0.4108 - val_loss: 1.0898 - val_accuracy: 0.4073\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0186 - accuracy: 0.4837\n",
      "Epoch 3: val_loss did not improve from 1.08983\n",
      "360/360 [==============================] - 19s 52ms/step - loss: 1.0186 - accuracy: 0.4837 - val_loss: 1.1194 - val_accuracy: 0.4096\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.8761 - accuracy: 0.5846\n",
      "Epoch 4: val_loss did not improve from 1.08983\n",
      "360/360 [==============================] - 15s 42ms/step - loss: 0.8761 - accuracy: 0.5846 - val_loss: 1.2447 - val_accuracy: 0.3933\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7139 - accuracy: 0.6817\n",
      "Epoch 5: val_loss did not improve from 1.08983\n",
      "360/360 [==============================] - 12s 33ms/step - loss: 0.7139 - accuracy: 0.6817 - val_loss: 1.4735 - val_accuracy: 0.3841\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.7572\n",
      "Epoch 6: val_loss did not improve from 1.08983\n",
      "360/360 [==============================] - 12s 32ms/step - loss: 0.5750 - accuracy: 0.7572 - val_loss: 1.7041 - val_accuracy: 0.3820\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.8123\n",
      "Epoch 7: val_loss did not improve from 1.08983\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 11s 31ms/step - loss: 0.4605 - accuracy: 0.8123 - val_loss: 1.8600 - val_accuracy: 0.3776\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 2028): 128.70 seconds (2.14 minutes)\n",
      "[Seed 2028] Val Loss: 1.0898 | Val Acc: 40.73%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train one model or an ensemble over seeds\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "os.makedirs(\"models_cnn_dual5_skip_drop\", exist_ok=True)\n",
    "cnn_models = []\n",
    "\n",
    "for seed in CFG.seeds:\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    model_path = os.path.join(\"models_cnn_dual5_skip_drop\", f\"cnn_dual_seed_{seed}.keras\")\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"âœ… Found existing model for seed {seed}, loading...\")\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    else:\n",
    "        print(f\"ðŸš€ Training new model for seed {seed}...\")\n",
    "        model = get_dual_cnn_model(vocab_size=vocab_size, embed_dim=64, num_classes=3)\n",
    "\n",
    "        ckpt = ModelCheckpoint(\n",
    "            filepath=model_path,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        es = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # --- Measure training time ---\n",
    "        t0 = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=30,\n",
    "            callbacks=[ckpt, es],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print(f\"â±ï¸ CNN Training time (seed {seed}): {(t1 - t0):.2f} seconds ({(t1 - t0)/60:.2f} minutes)\")\n",
    "        \n",
    "        # --- Reload best model (for consistency) ---\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # --- Evaluate on validation set ---\n",
    "    loss, acc = model.evaluate(val_ds, verbose=0)\n",
    "    print(f\"[Seed {seed}] Val Loss: {loss:.4f} | Val Acc: {acc*100:.2f}%\\n\")\n",
    "\n",
    "    # --- Store model for ensemble ---\n",
    "    cnn_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56514fb-870a-4c61-b9b3-c764b67ebd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models in cnn_models: 5\n",
      "Model 0 predictions shape: (11496, 3)\n",
      "Model 1 predictions shape: (11496, 3)\n",
      "Model 2 predictions shape: (11496, 3)\n",
      "Model 3 predictions shape: (11496, 3)\n",
      "Model 4 predictions shape: (11496, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of models in cnn_models: {len(cnn_models)}\")\n",
    "if len(cnn_models) > 0:\n",
    "    for i, m in enumerate(cnn_models):\n",
    "        preds = m.predict(val_ds, verbose=0)\n",
    "        print(f\"Model {i} predictions shape:\", preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc2bc23-f8e5-4abb-b723-d8464a6806cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (CNN)\n",
    "y_proba_val_cnn = np.mean([m.predict(val_ds,  verbose=0) for m in cnn_models], axis=0)\n",
    "y_pred_val_cnn  = y_proba_val_cnn.argmax(axis=1)\n",
    "\n",
    "# Test predictions + submission\n",
    "test_ds = make_dual_dataset(test_pairs, labels=None, training=False)\n",
    "\n",
    "y_proba_test_cnn = np.mean([m.predict(test_ds, verbose=0) for m in cnn_models], axis=0)\n",
    "y_pred_test_cnn  = y_proba_test_cnn.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb9f0b37-b10a-4f5b-bfa2-6906fcdd2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CNN5-Skip EVALUATION ================\n",
      "\n",
      "*** GLOBAL METRICS ***\n",
      "Accuracy (Global)      : 0.4327\n",
      "Precision (Macro Avg)  : 0.4405\n",
      "Recall (Macro Avg)     : 0.4252\n",
      "F1-Score (Macro Avg)   : 0.4151\n",
      "\n",
      "*** PER-CLASS EVALUATION ***\n",
      "Class                Precision    Recall  F1-Score   Support\n",
      "------------------------------------------------------------\n",
      "winner_model_a            0.42      0.57      0.49      4013\n",
      "winner_model_b            0.43      0.47      0.45      3931\n",
      "winner_tie                0.47      0.23      0.31      3552\n",
      "------------------------------------------------------------\n",
      "Macro Avg                 0.44      0.43      0.42     34488\n",
      "Weighted Avg              0.44      0.43      0.42     34488\n",
      "\n",
      "*** ROC-AUC EVALUATION ***\n",
      "ROC-AUC (OvR) : 0.5945\n",
      "\n",
      "*** LOG-LOSS EVALUATION ***\n",
      "Log-loss      : 1.0821\n",
      "\n",
      "*** LOG-LOSS PER CLASS ***\n",
      "Class 0: 1.0283  (n=4013)\n",
      "Class 1: 1.0490  (n=3931)\n",
      "Class 2: 1.1795  (n=3552)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ CNN5-Skip EVALUATION ================\\n\")\n",
    "# Metrics\n",
    "_ = eval_metrics(y_val, y_pred_val_cnn)\n",
    "eval_classification_report(y_val, y_pred_val_cnn, class_names)\n",
    "# ROC-AUC\n",
    "_ = eval_roc_auc(y_val, y_proba_val_cnn)\n",
    "# Log-loss\n",
    "_ = eval_log_loss(y_val, y_proba_val_cnn)\n",
    "_ = eval_log_loss_per_class(y_val, y_proba_val_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880a1e6c-1a5b-436f-bed9-2f29d04433f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      " [[2297 1268  448]\n",
      " [1593 1864  474]\n",
      " [1516 1223  813]]\n",
      "Saved plot to: images/confusion_matrix/confusion_matrix_cnn5s.png\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix + Plot\n",
    "cm_cnn = eval_confusion_matrix(y_val, y_pred_val_cnn, n_classes=y_proba_val_cnn.shape[1])\n",
    "plot_confusion_matrix(cm_cnn, class_names, title=\"Confusion Matrix â€” CNN5S\", save_path=\"results/confusion_matrix/confusion_matrix_cnn5s.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d4f7042-724d-48b0-9a67-9797aac5ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to: images/roc/roc_cnn5s.png\n"
     ]
    }
   ],
   "source": [
    "# ROC Curves\n",
    "plot_roc_curves(y_val, y_proba_val_cnn, class_names, title_prefix=\"CNN5S ROC\", save_path=\"results/roc/roc_cnn5s.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91e46aa-3068-40d2-89e9-46b1406caade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROC data for class 0 (AUC=0.6027) â†’ results/roc/CNN5S_fold1_class0.csv\n",
      "Saved ROC data for class 1 (AUC=0.6028) â†’ results/roc/CNN5S_fold1_class1.csv\n",
      "Saved ROC data for class 2 (AUC=0.5779) â†’ results/roc/CNN5S_fold1_class2.csv\n"
     ]
    }
   ],
   "source": [
    "save_roc_to_csv(y_val, y_proba_val_cnn, \"CNN5S\", fold_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb6dc0b-095c-47af-9c1e-4328cc34bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: results/submission/submission_cnn5s.csv\n"
     ]
    }
   ],
   "source": [
    "submission_cnn = build_submission(\n",
    "    test_df=test_df,\n",
    "    y_pred_test=y_pred_test_cnn,\n",
    "    y_proba_test=y_proba_test_cnn,\n",
    "    model_name=\"cnn5s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649f1bb-64aa-471b-87f8-253c4d98c253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
