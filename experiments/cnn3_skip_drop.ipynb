{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a04504e-4021-45ae-8788-580d052d089c",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725c3f52-e1fb-4978-81ce-933f9c928358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 02:03:05.005082: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-16 02:03:05.005154: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-16 02:03:05.006290: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-16 02:03:05.013947: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    log_loss\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import os, tensorflow as tf\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "from evaluation import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92942f37-3dbc-4623-aed3-d86bbd2debad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    TextVectorization, Embedding, Conv1D, GlobalMaxPooling1D,\n",
    "    Dense, Dropout, Input, MaxPooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d36760-c4a4-4fe8-95d5-169bdd75e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv A Example:\n",
      " What is a foreign exchange crisis? What are some notable examples?\n",
      "A foreign exchange crisis refers to a situation where a country faces severe shortage of foreign currencies, usually dollars or euros\n",
      "Conv B Example:\n",
      " What is a foreign exchange crisis? What are some notable examples?\n",
      "A foreign exchange crisis, also known as a currency crisis or balance of payments crisis, occurs when a country's currency experience\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "try:\n",
    "    CFG\n",
    "except NameError:\n",
    "    class CFG:\n",
    "        seeds = [42, 119, 2020, 2024, 2028]\n",
    "        \n",
    "train_df, test_df, y, class_names = load_and_prepare_data()\n",
    "pairs_train, pairs_val, test_pairs, y_train, y_val = prepare_dual_conversation_pipeline(train_df, test_df, y)\n",
    "\n",
    "print(\"Conv A Example:\\n\", pairs_train[0][0][:200])\n",
    "print(\"Conv B Example:\\n\", pairs_train[0][1][:200])\n",
    "print(\"Label:\", y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2742a2d4-9703-4121-b587-90d0c16518f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 02:03:20.889860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38367 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0\n",
      "2025-11-16 02:03:20.892132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38367 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer (shared across the two inputs)\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vocab_size = 20000\n",
    "max_length = 512\n",
    "\n",
    "adapt_strings = [p[0] for p in pairs_train] + [p[1] for p in pairs_train]\n",
    "adapt_ds = tf.data.Dataset.from_tensor_slices([str(t) for t in adapt_strings]).batch(1024)\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "text_vectorizer.adapt(adapt_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473d51b2-47dd-41c2-8710-ae061016ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.data pipelines for ((A,B), y)\n",
    "def make_dual_dataset(pairs, labels=None, batch_size=128, training=True):\n",
    "    part_a = [str(p[0]) for p in pairs]\n",
    "    part_b = [str(p[1]) for p in pairs]\n",
    "\n",
    "    inputs = {\"inp_a\": tf.constant(part_a), \"inp_b\": tf.constant(part_b)}\n",
    "\n",
    "    if labels is None:\n",
    "        ds = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "    else:\n",
    "        labels = np.asarray(labels, dtype=np.int32)\n",
    "        ds = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
    "\n",
    "    if labels is not None and training:\n",
    "        ds = ds.shuffle(2048, reshuffle_each_iteration=True)\n",
    "\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_dual_dataset(pairs_train, y_train, training=True)\n",
    "val_ds   = make_dual_dataset(pairs_val,   y_val,   training=False)\n",
    "test_ds  = make_dual_dataset(test_pairs,  labels=None,  training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62a1b71-9c02-4b24-8b25-c79cec2bdac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (two string inputs â†’ vectorizer â†’ shared embedding â†’ concat â†’ conv)\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, MaxPooling1D, Concatenate, Add\n",
    "\n",
    "def res_block(x, filters, use_projection=False):\n",
    "    shortcut = x\n",
    "    out = Conv1D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    out = Conv1D(filters, 3, padding=\"same\")(out)\n",
    "\n",
    "    if use_projection or shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding=\"same\")(shortcut)\n",
    "\n",
    "    out = Add()([out, shortcut])\n",
    "    out = tf.nn.relu(out)\n",
    "    return out\n",
    "    \n",
    "def conv_block(x, filters, use_residual=False, pool=True):\n",
    "    if use_residual:\n",
    "        x = res_block(x, filters, use_projection=True)\n",
    "    else:\n",
    "        x = Conv1D(filters, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    if pool:\n",
    "        x = MaxPooling1D()(x)\n",
    "    return x\n",
    "    \n",
    "def get_dual_cnn_model(vocab_size=vocab_size, embed_dim=64, num_classes=3):\n",
    "    inp_a = Input(shape=(), dtype=tf.string, name=\"inp_a\")\n",
    "    inp_b = Input(shape=(), dtype=tf.string, name=\"inp_b\")\n",
    "\n",
    "    # shared layers\n",
    "    emb = Embedding(input_dim=vocab_size, output_dim=embed_dim, mask_zero=True)\n",
    "\n",
    "    # branch A\n",
    "    xa = text_vectorizer(inp_a)\n",
    "    xa = emb(xa)\n",
    "    \n",
    "    # Conv32Ã—2 â†’ MP\n",
    "    xa = conv_block(xa, 32, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv64Ã—2 â†’ MP\n",
    "    xa = conv_block(xa, 64, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv128Ã—2 â†’ GMP\n",
    "    xa = conv_block(xa, 128, use_residual=True, pool=False)\n",
    "    xa = GlobalMaxPooling1D()(xa)\n",
    "\n",
    "    # branch B\n",
    "    xb = text_vectorizer(inp_b)\n",
    "    xb = emb(xb)\n",
    "\n",
    "    # Conv32Ã—2 â†’ MP\n",
    "    xb = conv_block(xb, 32, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv64Ã—2 â†’ MP\n",
    "    xb = conv_block(xb, 64, use_residual=True, pool=True)\n",
    "\n",
    "    # Conv128Ã—2 â†’ GMP\n",
    "    xb = conv_block(xb, 128, use_residual=True, pool=False)\n",
    "    xb = GlobalMaxPooling1D()(xb)\n",
    "    \n",
    "    # merge\n",
    "    x  = Concatenate()([xa, xb])\n",
    "    x  = Dropout(0.3)(x)\n",
    "    x  = Dense(256, activation=\"swish\")(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=[inp_a, inp_b], outputs=out)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da7f1d1-23be-41a0-9f7b-4c4c61bcc7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training new model for seed 42...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-16 02:03:29.426762: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-11-16 02:03:29.898030: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-11-16 02:03:29.975967: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-11-16 02:03:31.247927: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ff1c7f5aaa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-16 02:03:31.247964: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2025-11-16 02:03:31.247969: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2025-11-16 02:03:31.253859: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763280211.328779 1238941 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - ETA: 0s - loss: 1.0915 - accuracy: 0.3785\n",
      "Epoch 1: val_loss improved from inf to 1.07728, saving model to models_cnn_dual3_skip/cnn_dual_seed_42.keras\n",
      "360/360 [==============================] - 46s 108ms/step - loss: 1.0915 - accuracy: 0.3785 - val_loss: 1.0773 - val_accuracy: 0.4188\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0525 - accuracy: 0.4529\n",
      "Epoch 2: val_loss improved from 1.07728 to 1.07025, saving model to models_cnn_dual3_skip/cnn_dual_seed_42.keras\n",
      "360/360 [==============================] - 29s 79ms/step - loss: 1.0525 - accuracy: 0.4529 - val_loss: 1.0702 - val_accuracy: 0.4328\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9338 - accuracy: 0.5485\n",
      "Epoch 3: val_loss did not improve from 1.07025\n",
      "360/360 [==============================] - 22s 61ms/step - loss: 0.9338 - accuracy: 0.5485 - val_loss: 1.2240 - val_accuracy: 0.4176\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7422 - accuracy: 0.6619\n",
      "Epoch 4: val_loss did not improve from 1.07025\n",
      "360/360 [==============================] - 19s 54ms/step - loss: 0.7422 - accuracy: 0.6619 - val_loss: 1.4627 - val_accuracy: 0.4121\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5605 - accuracy: 0.7614\n",
      "Epoch 5: val_loss did not improve from 1.07025\n",
      "360/360 [==============================] - 12s 34ms/step - loss: 0.5605 - accuracy: 0.7614 - val_loss: 1.8084 - val_accuracy: 0.3907\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4221 - accuracy: 0.8281\n",
      "Epoch 6: val_loss did not improve from 1.07025\n",
      "360/360 [==============================] - 13s 35ms/step - loss: 0.4221 - accuracy: 0.8281 - val_loss: 2.3240 - val_accuracy: 0.3887\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.3331 - accuracy: 0.8710\n",
      "Epoch 7: val_loss did not improve from 1.07025\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 11s 29ms/step - loss: 0.3331 - accuracy: 0.8710 - val_loss: 2.3817 - val_accuracy: 0.3912\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 42): 151.12 seconds (2.52 minutes)\n",
      "[Seed 42] Val Loss: 1.0702 | Val Acc: 43.28%\n",
      "\n",
      "ðŸš€ Training new model for seed 119...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0928 - accuracy: 0.3771\n",
      "Epoch 1: val_loss improved from inf to 1.08542, saving model to models_cnn_dual3_skip/cnn_dual_seed_119.keras\n",
      "360/360 [==============================] - 36s 88ms/step - loss: 1.0928 - accuracy: 0.3771 - val_loss: 1.0854 - val_accuracy: 0.3934\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0618 - accuracy: 0.4372\n",
      "Epoch 2: val_loss did not improve from 1.08542\n",
      "360/360 [==============================] - 23s 63ms/step - loss: 1.0618 - accuracy: 0.4372 - val_loss: 1.0904 - val_accuracy: 0.4145\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9706 - accuracy: 0.5228\n",
      "Epoch 3: val_loss did not improve from 1.08542\n",
      "360/360 [==============================] - 17s 46ms/step - loss: 0.9706 - accuracy: 0.5228 - val_loss: 1.1941 - val_accuracy: 0.4171\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7965 - accuracy: 0.6348\n",
      "Epoch 4: val_loss did not improve from 1.08542\n",
      "360/360 [==============================] - 15s 41ms/step - loss: 0.7965 - accuracy: 0.6348 - val_loss: 1.4313 - val_accuracy: 0.3963\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5955 - accuracy: 0.7421\n",
      "Epoch 5: val_loss did not improve from 1.08542\n",
      "360/360 [==============================] - 14s 38ms/step - loss: 0.5955 - accuracy: 0.7421 - val_loss: 1.7197 - val_accuracy: 0.3965\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4511 - accuracy: 0.8188\n",
      "Epoch 6: val_loss did not improve from 1.08542\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 11s 31ms/step - loss: 0.4511 - accuracy: 0.8188 - val_loss: 2.0461 - val_accuracy: 0.3734\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 119): 114.71 seconds (1.91 minutes)\n",
      "[Seed 119] Val Loss: 1.0854 | Val Acc: 39.34%\n",
      "\n",
      "ðŸš€ Training new model for seed 2020...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0916 - accuracy: 0.3757\n",
      "Epoch 1: val_loss improved from inf to 1.07658, saving model to models_cnn_dual3_skip/cnn_dual_seed_2020.keras\n",
      "360/360 [==============================] - 35s 85ms/step - loss: 1.0916 - accuracy: 0.3757 - val_loss: 1.0766 - val_accuracy: 0.4181\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0608 - accuracy: 0.4405\n",
      "Epoch 2: val_loss did not improve from 1.07658\n",
      "360/360 [==============================] - 23s 63ms/step - loss: 1.0608 - accuracy: 0.4405 - val_loss: 1.0826 - val_accuracy: 0.4265\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9646 - accuracy: 0.5325\n",
      "Epoch 3: val_loss did not improve from 1.07658\n",
      "360/360 [==============================] - 17s 48ms/step - loss: 0.9646 - accuracy: 0.5325 - val_loss: 1.1641 - val_accuracy: 0.4280\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7725 - accuracy: 0.6494\n",
      "Epoch 4: val_loss did not improve from 1.07658\n",
      "360/360 [==============================] - 14s 38ms/step - loss: 0.7725 - accuracy: 0.6494 - val_loss: 1.4047 - val_accuracy: 0.4035\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.7648\n",
      "Epoch 5: val_loss did not improve from 1.07658\n",
      "360/360 [==============================] - 12s 34ms/step - loss: 0.5611 - accuracy: 0.7648 - val_loss: 1.7013 - val_accuracy: 0.4077\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.8390\n",
      "Epoch 6: val_loss did not improve from 1.07658\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 11s 29ms/step - loss: 0.4025 - accuracy: 0.8390 - val_loss: 2.0740 - val_accuracy: 0.4056\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 2020): 111.45 seconds (1.86 minutes)\n",
      "[Seed 2020] Val Loss: 1.0766 | Val Acc: 41.81%\n",
      "\n",
      "ðŸš€ Training new model for seed 2024...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0906 - accuracy: 0.3814\n",
      "Epoch 1: val_loss improved from inf to 1.08356, saving model to models_cnn_dual3_skip/cnn_dual_seed_2024.keras\n",
      "360/360 [==============================] - 35s 86ms/step - loss: 1.0906 - accuracy: 0.3814 - val_loss: 1.0836 - val_accuracy: 0.4034\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0523 - accuracy: 0.4486\n",
      "Epoch 2: val_loss did not improve from 1.08356\n",
      "360/360 [==============================] - 22s 62ms/step - loss: 1.0523 - accuracy: 0.4486 - val_loss: 1.1393 - val_accuracy: 0.3965\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9279 - accuracy: 0.5559\n",
      "Epoch 3: val_loss did not improve from 1.08356\n",
      "360/360 [==============================] - 18s 50ms/step - loss: 0.9279 - accuracy: 0.5559 - val_loss: 1.1831 - val_accuracy: 0.4238\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7127 - accuracy: 0.6834\n",
      "Epoch 4: val_loss did not improve from 1.08356\n",
      "360/360 [==============================] - 12s 34ms/step - loss: 0.7127 - accuracy: 0.6834 - val_loss: 1.4976 - val_accuracy: 0.4009\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.7832\n",
      "Epoch 5: val_loss did not improve from 1.08356\n",
      "360/360 [==============================] - 13s 37ms/step - loss: 0.5224 - accuracy: 0.7832 - val_loss: 1.9026 - val_accuracy: 0.4012\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.8466\n",
      "Epoch 6: val_loss did not improve from 1.08356\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "360/360 [==============================] - 10s 29ms/step - loss: 0.3855 - accuracy: 0.8466 - val_loss: 2.2025 - val_accuracy: 0.3928\n",
      "Epoch 6: early stopping\n",
      "â±ï¸ CNN Training time (seed 2024): 111.51 seconds (1.86 minutes)\n",
      "[Seed 2024] Val Loss: 1.0836 | Val Acc: 40.34%\n",
      "\n",
      "ðŸš€ Training new model for seed 2028...\n",
      "Epoch 1/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0922 - accuracy: 0.3757\n",
      "Epoch 1: val_loss improved from inf to 1.07576, saving model to models_cnn_dual3_skip/cnn_dual_seed_2028.keras\n",
      "360/360 [==============================] - 34s 83ms/step - loss: 1.0922 - accuracy: 0.3757 - val_loss: 1.0758 - val_accuracy: 0.4171\n",
      "Epoch 2/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 1.0569 - accuracy: 0.4478\n",
      "Epoch 2: val_loss improved from 1.07576 to 1.07274, saving model to models_cnn_dual3_skip/cnn_dual_seed_2028.keras\n",
      "360/360 [==============================] - 22s 61ms/step - loss: 1.0569 - accuracy: 0.4478 - val_loss: 1.0727 - val_accuracy: 0.4314\n",
      "Epoch 3/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.9453 - accuracy: 0.5449\n",
      "Epoch 3: val_loss did not improve from 1.07274\n",
      "360/360 [==============================] - 17s 46ms/step - loss: 0.9453 - accuracy: 0.5449 - val_loss: 1.1925 - val_accuracy: 0.4270\n",
      "Epoch 4/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.7347 - accuracy: 0.6702\n",
      "Epoch 4: val_loss did not improve from 1.07274\n",
      "360/360 [==============================] - 15s 41ms/step - loss: 0.7347 - accuracy: 0.6702 - val_loss: 1.4287 - val_accuracy: 0.4181\n",
      "Epoch 5/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.7804\n",
      "Epoch 5: val_loss did not improve from 1.07274\n",
      "360/360 [==============================] - 12s 35ms/step - loss: 0.5304 - accuracy: 0.7804 - val_loss: 1.8076 - val_accuracy: 0.4081\n",
      "Epoch 6/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8432\n",
      "Epoch 6: val_loss did not improve from 1.07274\n",
      "360/360 [==============================] - 10s 29ms/step - loss: 0.3946 - accuracy: 0.8432 - val_loss: 2.0806 - val_accuracy: 0.4077\n",
      "Epoch 7/30\n",
      "360/360 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8851\n",
      "Epoch 7: val_loss did not improve from 1.07274\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "360/360 [==============================] - 10s 29ms/step - loss: 0.2983 - accuracy: 0.8851 - val_loss: 2.3056 - val_accuracy: 0.3992\n",
      "Epoch 7: early stopping\n",
      "â±ï¸ CNN Training time (seed 2028): 120.98 seconds (2.02 minutes)\n",
      "[Seed 2028] Val Loss: 1.0727 | Val Acc: 43.14%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train one model or an ensemble over seeds\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "os.makedirs(\"models_cnn_dual3_skip_drop\", exist_ok=True)\n",
    "cnn_models = []\n",
    "\n",
    "for seed in CFG.seeds:\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    model_path = os.path.join(\"models_cnn_dual3_skip_drop\", f\"cnn_dual_seed_{seed}.keras\")\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"âœ… Found existing model for seed {seed}, loading...\")\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "    else:\n",
    "        print(f\"ðŸš€ Training new model for seed {seed}...\")\n",
    "        model = get_dual_cnn_model(vocab_size=vocab_size, embed_dim=64, num_classes=3)\n",
    "\n",
    "        ckpt = ModelCheckpoint(\n",
    "            filepath=model_path,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        es = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # --- Measure training time ---\n",
    "        t0 = time.time()\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=30,\n",
    "            callbacks=[ckpt, es],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print(f\"â±ï¸ CNN Training time (seed {seed}): {(t1 - t0):.2f} seconds ({(t1 - t0)/60:.2f} minutes)\")\n",
    "        \n",
    "        # --- Reload best model (for consistency) ---\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # --- Evaluate on validation set ---\n",
    "    loss, acc = model.evaluate(val_ds, verbose=0)\n",
    "    print(f\"[Seed {seed}] Val Loss: {loss:.4f} | Val Acc: {acc*100:.2f}%\\n\")\n",
    "\n",
    "    # --- Store model for ensemble ---\n",
    "    cnn_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56514fb-870a-4c61-b9b3-c764b67ebd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models in cnn_models: 5\n",
      "Model 0 predictions shape: (11496, 3)\n",
      "Model 1 predictions shape: (11496, 3)\n",
      "Model 2 predictions shape: (11496, 3)\n",
      "Model 3 predictions shape: (11496, 3)\n",
      "Model 4 predictions shape: (11496, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of models in cnn_models: {len(cnn_models)}\")\n",
    "if len(cnn_models) > 0:\n",
    "    for i, m in enumerate(cnn_models):\n",
    "        preds = m.predict(val_ds, verbose=0)\n",
    "        print(f\"Model {i} predictions shape:\", preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc2bc23-f8e5-4abb-b723-d8464a6806cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions (CNN)\n",
    "y_proba_val_cnn = np.mean([m.predict(val_ds,  verbose=0) for m in cnn_models], axis=0)\n",
    "y_pred_val_cnn  = y_proba_val_cnn.argmax(axis=1)\n",
    "\n",
    "# Test predictions + submission\n",
    "test_ds = make_dual_dataset(test_pairs, labels=None, training=False)\n",
    "\n",
    "y_proba_test_cnn = np.mean([m.predict(test_ds, verbose=0) for m in cnn_models], axis=0)\n",
    "y_pred_test_cnn  = y_proba_test_cnn.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb9f0b37-b10a-4f5b-bfa2-6906fcdd2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CNN3-Skip EVALUATION ================\n",
      "\n",
      "*** GLOBAL METRICS ***\n",
      "Accuracy (Global)      : 0.4529\n",
      "Precision (Macro Avg)  : 0.4522\n",
      "Recall (Macro Avg)     : 0.4456\n",
      "F1-Score (Macro Avg)   : 0.4365\n",
      "\n",
      "*** PER-CLASS EVALUATION ***\n",
      "Class                Precision    Recall  F1-Score   Support\n",
      "------------------------------------------------------------\n",
      "winner_model_a            0.46      0.54      0.50      4013\n",
      "winner_model_b            0.45      0.54      0.49      3931\n",
      "winner_tie                0.45      0.25      0.32      3552\n",
      "------------------------------------------------------------\n",
      "Macro Avg                 0.45      0.45      0.44     34488\n",
      "Weighted Avg              0.45      0.45      0.44     34488\n",
      "\n",
      "*** ROC-AUC EVALUATION ***\n",
      "ROC-AUC (OvR) : 0.6208\n",
      "\n",
      "*** LOG-LOSS EVALUATION ***\n",
      "Log-loss      : 1.0625\n",
      "\n",
      "*** LOG-LOSS PER CLASS ***\n",
      "Class 0: 1.0258  (n=4013)\n",
      "Class 1: 1.0159  (n=3931)\n",
      "Class 2: 1.1554  (n=3552)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ CNN3-Skip EVALUATION ================\\n\")\n",
    "# Metrics\n",
    "_ = eval_metrics(y_val, y_pred_val_cnn)\n",
    "eval_classification_report(y_val, y_pred_val_cnn, class_names)\n",
    "# ROC-AUC\n",
    "_ = eval_roc_auc(y_val, y_proba_val_cnn)\n",
    "# Log-loss\n",
    "_ = eval_log_loss(y_val, y_proba_val_cnn)\n",
    "_ = eval_log_loss_per_class(y_val, y_proba_val_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880a1e6c-1a5b-436f-bed9-2f29d04433f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      " [[2183 1296  534]\n",
      " [1244 2142  545]\n",
      " [1317 1354  881]]\n",
      "Saved plot to: images/confusion_matrix/confusion_matrix_cnn3s.png\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix + Plot\n",
    "cm_cnn = eval_confusion_matrix(y_val, y_pred_val_cnn, n_classes=y_proba_val_cnn.shape[1])\n",
    "plot_confusion_matrix(cm_cnn, class_names, title=\"Confusion Matrix â€” CNN3S\", save_path=\"results/confusion_matrix/confusion_matrix_cnn3s.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d4f7042-724d-48b0-9a67-9797aac5ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to: images/roc/roc_cnn3s.png\n"
     ]
    }
   ],
   "source": [
    "# ROC Curves\n",
    "plot_roc_curves(y_val, y_proba_val_cnn, class_names, title_prefix=\"CNN3S ROC\", save_path=\"results/roc/roc_cnn3s.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91e46aa-3068-40d2-89e9-46b1406caade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROC data for class 0 (AUC=0.6385) â†’ results/roc/CNN3S_fold1_class0.csv\n",
      "Saved ROC data for class 1 (AUC=0.6382) â†’ results/roc/CNN3S_fold1_class1.csv\n",
      "Saved ROC data for class 2 (AUC=0.5858) â†’ results/roc/CNN3S_fold1_class2.csv\n"
     ]
    }
   ],
   "source": [
    "save_roc_to_csv(y_val, y_proba_val_cnn, \"CNN3S\", fold_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb6dc0b-095c-47af-9c1e-4328cc34bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: results/submission/submission_cnn3s.csv\n"
     ]
    }
   ],
   "source": [
    "submission_cnn = build_submission(\n",
    "    test_df=test_df,\n",
    "    y_pred_test=y_pred_test_cnn,\n",
    "    y_proba_test=y_proba_test_cnn,\n",
    "    model_name=\"cnn3s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649f1bb-64aa-471b-87f8-253c4d98c253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
